{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriScale - Seasonal Components\n",
    "\n",
    "> This notebook is intended for **self-study** of _TriScale._  \n",
    "Here is the [version for live sessions](live_seasonal-comp.ipynb).\n",
    "\n",
    "This notebook contains tutorial materials for _TriScale_. \n",
    "\n",
    "More specifically, this notebook presents the importance of accounting for seasonal components  \n",
    "in the data analysis.\n",
    "\n",
    "> If you don't know about Jupyter Notebooks and how to interact with them,  \n",
    "fear not! We compiled everything that you need to know here: [Notebook Basics](tutorial_notebook-basics.ipynb) :-) \n",
    "\n",
    "\n",
    "For more details about _TriScale,_ you may refer to [the paper](https://doi.org/10.5281/zenodo.3464273).\n",
    "\n",
    "---\n",
    "- [Scenario](#Scenario)\n",
    "    - [Scenario details](#Scenario-details)\n",
    "    - [The dataset](#The-dataset)\n",
    "- [Data analysis](#Data-analysis)  \n",
    "    - [Your turn: time to practice (part 1)](#Your-turn:-time-to-practice-(part-1))  \n",
    "    - [What about seasonality?](#What-about-seasonality?)  \n",
    "    - [Your turn: time to practice (part 2)](#Your-turn:-time-to-practice-(part-2))  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we need to import a few Python modules.  \n",
    "All the _TriScale_-specific functions are part of one module called `triscale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import triscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we are ready to analyse some data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "In this tutorial, we consider performance data from [Glossy](https://ieeexplore.ieee.org/document/5779066) collected on [the FlockLab testbed](http://flocklab.ethz.ch/)  \n",
    "as experiment environment. \n",
    "\n",
    "[Glossy](https://ieeexplore.ieee.org/document/5779066) is a low-power wireless protocol based on synchronous transmissions and a  \n",
    "flooding strategy. One important tuning parameter of Glossy is the number of times  \n",
    "$N$ that each node transmit each packet.\n",
    "\n",
    "The literature reports that larger $N$ yields better reliability; that is, a larger packet  \n",
    "reception ratio (PRR). We performed a short experimental study to validate this  observation.   \n",
    "More specifically, we test two values:\n",
    "- $N=1$\n",
    "- $N=2$\n",
    "\n",
    "### Scenario details\n",
    "\n",
    "> **Note.** These details are irrelevant for the present tutorial and are  \n",
    "only provided for completeness. Feel free to skip that section...\n",
    "\n",
    "<details>\n",
    "  <summary>Click here show the details</summary>\n",
    "  \n",
    "The test scenario is very simple. During one communication round, each node in the network initiate in turn a Glossy flood (using $N=1$ retransmission). All the other nodes log whether they successfully received the packet. The same round is then repeated with $N=2$ retransmissions.\n",
    "\n",
    "- The evaluation runs on the [TelosB motes](https://www.advanticsys.com/shop/mtmcm5000msp-p-14.html)\n",
    "- The motes use radio frequency channel 22 (2.46GHz, which largely overlaps with WiFi traffic)\n",
    "- The payload size is set to 64 bytes.\n",
    "- The scenario is run 24 times per day, scheduled randomly throughout the day. \n",
    "- Data has been collected over three weeks, from 2019-08-22 to 2019-09-11.\n",
    "\n",
    "We define the PRR metric as the median packet reception ratio between all the nodes. In other words, our metric is the median number of floods what are successfully received by one node in the network.\n",
    "</details>\n",
    "\n",
    "\n",
    "### The dataset\n",
    "\n",
    "The collected data is available in the [TriScale artifacts repository](#Download-Source-Files-and-Data). The results have been  \n",
    "collected, processed, and made directly available for analysis. Let's first load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PRR results from the test\n",
    "df = pd.read_csv('ExampleData/metrics_glossy.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Display a random sample\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To limit bias, the dataset has been \"anonymized;\" that is, we randomly replaced the  \n",
    "value of $N$ with a letter ($A$ or $B$).\n",
    "\n",
    "## Data analysis\n",
    "\n",
    "### Your turn: time to practice (part 1)\n",
    "\n",
    "The FlockLab testbed is located in an office building, where we expect more wireless  \n",
    "interference during the day than during the night. Thus, for a fair comparison, the   \n",
    "time span of a series of runs should be at least one day (24 hours).\n",
    "\n",
    "Let us select two days and compare the PRR of $A$ and $B$ on those days.  \n",
    "The KPI definition is given below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days considered for the data analysis\n",
    "day_A = '2019-08-24'\n",
    "day_B = '2019-08-26'\n",
    "\n",
    "# Fitering the dataset for the data or interest\n",
    "data_A = df.loc[day_A].PRR_A.dropna().values\n",
    "data_B = df.loc[day_B].PRR_B.dropna().values\n",
    "\n",
    "# KPI definition\n",
    "KPI = {'name': 'PRR',\n",
    "       'unit': '\\%',\n",
    "       'percentile': 50,\n",
    "       'confidence': 95,\n",
    "       'class': 'one-sided',\n",
    "       'bounds': [0,100],\n",
    "       'bound': 'lower'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `triscale.analysis_kpi()` function to compute the KPI value for each group. \n",
    "\n",
    "- Which group seems to perform best?\n",
    "- What confidence to you have in this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## YOUR CODE HERE ###########\n",
    "# ...\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions\n",
    "\n",
    "<details>\n",
    "  <summary><br/>Click here show the solutions</summary>\n",
    "  \n",
    "```python\n",
    ">>> triscale.analysis_kpi(data_A, KPI)\n",
    "(True, 88.0)\n",
    ">>> triscale.analysis_kpi(data_B, KPI)\n",
    "(True, 84.0)\n",
    "```\n",
    "$A$ seems to perform better than $B$. However, since even if the KPI has been defined  \n",
    "with a high level of confidence, it does not mean that the experimental conditions  \n",
    "during the two days were actually comparable...\n",
    "    \n",
    "And as a matter of fact, $A$ corresponds to $N=1$ which is highly unlikely to perform  \n",
    "   better than $N=2$.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about seasonality? \n",
    "\n",
    "In the previous analysis, we (randomly?) picked some days for each group. But what   \n",
    "do we know about the possible correlation between those two days? \n",
    "- Maybe we got unlucky on the day $B$ was tested?\n",
    "- Or maybe we omitted some hidden factor?\n",
    "\n",
    "To investigate that, we can look at the [wireless link quality data for FlockLab](https://doi.org/10.5281/zenodo.3354717), which is   \n",
    "collected by the FlockLab maintainers and made publicly available. They ran the link  \n",
    "quality tests every two hours, resulting in 12 measurement points per day.\n",
    "\n",
    "In this tutorial, we look at the data from August 2019, which has a large overlap with  \n",
    "our data collection period. Let's load this dataset and have a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_quality = pd.read_csv('ExampleData/flocklab_link_quality.csv', index_col=0, parse_dates=True)\n",
    "link_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is simple: every two hours, we have one value representing the \"average  \n",
    "link quality\" on the testbed (the computation that led to this average is irrelevant here).\n",
    "\n",
    "_TriScale_'s `network_profiling()` generates an autocorellation plot based on  \n",
    "such data, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_quality_bounds = [0,100]\n",
    "link_quality_name = 'PRR [%]'\n",
    "fig_theil, fig_autocorr = triscale.network_profiling(\n",
    "    link_quality, \n",
    "    link_quality_bounds, \n",
    "    link_quality_name,\n",
    ")\n",
    "fig_autocorr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can clearly see from the autocorrelation plot that the average link quality on  \n",
    "FlockLab has strong seasonal components. The **first pic at lag 12 (i.e., 24h)**  \n",
    "reveals the daily seasonal component. \n",
    "\n",
    "But there is also **a second main peak at lag 84**; which corresponds to one week.  \n",
    "Indeed, there is less interference in the weekends than on weekdays, which creates  \n",
    "a weekly seasonal component.\n",
    "\n",
    "Due to this weekly component, it becomes problematic (aka, potentially wrong) to  \n",
    "compare results from different time periods which span less than a week.  \n",
    "In other word, the time span for series of runs must be at least one week long  \n",
    "to be fairly comparable.\n",
    "\n",
    "Let us quickly check which days of the week we picked for our first analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weekday(str):\n",
    "    '''Simple function printing the weekday\n",
    "    from a date given as a string\n",
    "    '''\n",
    "    year, month, day  = (int(x) for x in str.split('-'))    \n",
    "    ans = datetime.date(year, month, day)\n",
    "    print(ans.strftime(\"%A\"))\n",
    "    \n",
    "print_weekday(day_A)\n",
    "print_weekday(day_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo! $B$ was tested on a weekday, while $A$ was tested on a weekend...\n",
    "\n",
    "> The day of the week was a \"hidden\" factor in our first analysis.  \n",
    "Neglecting it led to wrong conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn: time to practice (part 2)\n",
    "\n",
    "Let us now use the entire Glossy dataset and analyse it as one series  \n",
    "(with a span of three weeks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A = df.PRR_A.dropna().values\n",
    "data_B = df.PRR_B.dropna().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use again the `triscale.analysis_kpi()` function to compute  \n",
    "the KPI value for each group.\n",
    "- Which group seems to perform best now?\n",
    "- What about independence? Do you think the results are trustworthy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## YOUR CODE HERE ###########\n",
    "# ...\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions\n",
    "\n",
    "<details>\n",
    "  <summary><br/>Click here to show the solutions</summary>\n",
    "  \n",
    "```python\n",
    ">>> triscale.analysis_kpi(data_A, KPI)\n",
    "(False, 80.0)\n",
    ">>> triscale.analysis_kpi(data_B, KPI)\n",
    "(False, 88.0)\n",
    "```\n",
    "Now, we do obtain the expected result: $N=2$ (group $B$) performs better than $N=1$.  \n",
    "    Note however that the independence test fails. This is due to the ordering of the tests:  \n",
    "    We scheduled tests randomly every day individually, not over the 3 weeks time span.  \n",
    "    Therefore, the data are affected by the (strong) weekly correlation on the environment.\n",
    "    \n",
    "We can observe this correlation bt plotting the data and/or it's autocorellation function:\n",
    "```python\n",
    ">>> plots=['series','autocorr']\n",
    ">>> triscale.analysis_kpi(data_A, KPI, plots)\n",
    "```\n",
    "    \n",
    "We can try to emulate the fact that we'd have properly randomized the run epochs by shuffling  \n",
    "    the data.\n",
    "    \n",
    "```python\n",
    ">>> import random\n",
    ">>> random.shuffle(data_A)\n",
    ">>> to_plot=['autocorr']\n",
    ">>> triscale.analysis_kpi(data_A, KPI, to_plot)\n",
    "```  \n",
    "    \n",
    "As you can see, the correlation structure significantly flattens. In some cases, the independence  \n",
    "test might even pass... But keep in mind it is only an artifact! To make a strong statement,  \n",
    "    the run epochs should have been truly randomized.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "[Back to main repository](.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('triscale': conda)",
   "language": "python",
   "name": "python391jvsc74a57bd0684f90775fb1f43db0d8eed0780ba829f42a97c2f4b9a1bd592c18e47e5c272e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "684f90775fb1f43db0d8eed0780ba829f42a97c2f4b9a1bd592c18e47e5c272e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
